---
layout: dirindex
fb_comments: 3
---

## Code packages 

+ (Bi-) Factored Gradient Descent algorithm for low-rank recovery (Matlab - to be updated)
  
  <!---<button id="b_des_s8"> Description </button>-->
  <button id="b_dow_s8"> Download </button>
  <button id="b_pap_s8"> Paper </button>
   <p id="des_s8"> <i> This software package is a proof of concept for $UV^\top$ parameterization 
   in optimization and focuses on first-order, gradient descent algorithmic solutions for the case
   of matrix sensing. The algorithm proposed is named as Bi-Factored Gradient Descent (BFGD) algorithm, 
   an efficient first-order method that operates on the $U, V$ factors. 
   
   Subsequent versions will include more involved applications such as 1-bit matrix completion (logistic
   regression objective), low-rank image recovery from limited measurements, quantum state tomography
   settings, etc.   
    </i> </p>

+ A simple, but yet efficient, algorithm for Bipartite Correlation Clustering (Matlab)
  
  <!---<button id="b_des_s10"> Description </button>-->
  <button id="b_dow_s10"> Download </button>
  <button id="b_pap_s10"> Paper </button>
   <p id="des_s10"> <i> In this code, we implement a simple, yet efficient, algorithm for the problem
   of Bipartite Correlation Clustering (BCC). Our algorithm solves a more generalized problem of 
   maximizing a bilinear form, a specific instance of which is the BCC problem. In the demo included,
   we run our algorithm on a small movie lense dataset, in order to automatically extract useful clusters
   between users that have similar movie preferences.
    </i> </p>


+ ALgebraic PursuitS (ALPS) for sparse signal recovery (Matlab)
  
  <!---<button id="b_des_s1"> Description </button>-->
  <button id="b_dow_s1"> Download </button>
  <button id="b_pap_s1"> Paper </button>
   <p id="des_s1"> <i> This software package implements the ALgebraic PursuitS class of methods for sparse signal recovery.
   ALPS framework includes some of the fastest Iterative Hard Thresholding (IHT) variants, 
   utilizing optimal subspace exploration, cheap and adaptive step size selection and Nesterov-style accelerations.
   ALPS are also backed with strong theoretical guarantees, based on RIP assumptions in compressed sensing settings.
    </i> </p>
   
   
+ Matrix ALgebraic PursuitS (Matrix ALPS) for low rank recovery (Matlab)
  
  <!---<button id="b_des_s2"> Description </button>-->
  <button id="b_dow_s2"> Download </button>
  <button id="b_pap_s2"> Paper </button>
   <p id="des_s2"> <i> This software package implements the Matrix ALgebraic PursuitS class of methods for low rank recovery.
   This set of problems includes the affine rank minimization, matrix completion and PCA settings.
   Similar to the vectors case, the Matrix ALPS framework includes some of the fastest Iterative Hard Thresholding (IHT) variants
   for low rank matrix reconstruction, 
   utilizing optimal subspace exploration, cheap and adaptive step size selection and Nesterov-style accelerations.
   Matrix ALPS are also backed with strong theoretical guarantees, based on RIP assumptions in compressed sensing settings.
    </i> </p>
   

+ Matrix ALgebraic PursuitS (Matrix ALPS) for low rank + sparse recovery (Matlab)
  
  <!---<button id="b_des_s3"> Description </button>-->
  <button id="b_dow_s3"> Download </button>
  <button id="b_pap_s3"> Paper </button>
   <p id="des_s3"> <i> This software package is the extension of the Matrix ALPS software package for the case of
   low rank and sparse recovery. Applications include background video subtraction and robust PCA, among others.
    </i> </p>
    
+ Self-Concordant OPTimization (SCOPT) for composite convex problems (Matlab)
  
  <!---<button id="b_des_s4"> Description </button>-->
  <button id="b_dow_s4"> Link to software </button>
  <button id="b_pap_s4a"> Paper #1</button>
  <button id="b_pap_s4b"> Paper #2</button>
   <p id="des_s4"> <i> SCOPT is a MATLAB implementation of the proximal gradient, proximal 
   quasi-Newton, proximal Newton, and path-following interior-point algorithms for solving 
   composite convex minimization problems involving self-concordant and self-concordant-like functions.
    </i> </p>
    
+ Provable deterministic leverage scores sampling (Matlab)

  <!---<button id="b_des_s11"> Description </button>-->
  <button id="b_dow_s11"> Download </button>
  <button id="b_pap_s11"> Paper </button>
   <p id="des_s11"> <i> Here, we explain in practice the curious empirical phenomenon: 
    “Approximating a matrix by deterministically selecting a subset of its columns with 
    the corresponding largest leverage scores results in a good low-rank matrix surrogate”. 
    In this demo, we demonstrate empirically the 
    performance of deterministic leverage score sampling, which many times
    matches or outperforms the state-of-the-art techniques.
    </i> </p>
    
+ Generalized Sparse Additive Models (GSPAM) with interactions in high-dimensions (Matlab)

  <!---<button id="b_des_s9"> Description </button>-->
  <button id="b_dow_s9"> Download </button>
  <button id="b_pap_s9"> Paper </button>
   <p id="des_s9"> <i> This software package solves a d-dimensional GSPAM instance, where
   univariate and bivariate set of indices ($S_1$ and $S_2$, respectively) are unknowns. 
   The code follows the steps indicated by the main algorithm, described in the conference paper.
    </i> </p>
    
+ Expanders and group sparse recovery (Matlab)

  <!---<button id="b_des_s5"> Description </button>-->
  <button id="b_dow_s5"> Download </button>
  <button id="b_pap_s5"> Paper </button>
   <p id="des_s5"> <i> Proof of concept why expanders accelerate execution time of convex solvers for group sparse
   recovery. The problem setting is that of group sparse convex norm minimization over linear constraints.
   The experiments include both synthetic and real data settings. 
    </i> </p>
    
+ Finding the M-PSK vector that maximizes a rank-deficient complex quadratic form (Matlab - to be updated)

  <!---<button id="b_des_s6"> Description </button>-->
  <button id="b_dow_s6"> Download </button>
  <button id="b_pap_s6"> Paper </button>
   <p id="des_s6"> <i> Given a rank-deficient PSD complex matrix as an input, computes the 
   polynomial-sized set of candidate M-PSK solutions, among which the
   optimal M-PSK vector --that maximizes the rank-deficient quadratic form-- lies. 
  </i> </p>
  
+ Multiway (tensor) compressed sensing for sparse and low rank tensors (Matlab)

  <!---<button id="b_des_s7"> Description </button>-->
  <button id="b_dow_s7"> Download </button>
  <button id="b_pap_s7"> Paper </button>
   <p id="des_s7"> <i> In this contribution, we consider
	compressed sensing for sparse and low-rank tensors. More specifically,
	we consider low-rank tensors synthesized as sums of outer products
	of sparse loading vectors, and a special class of linear dimensionality-reducing
	transformations that reduce each mode individually. We prove
	interesting "oracle" properties showing that it is possible to identify
	the uncompressed sparse loadings directly from the compressed tensor data.
	
	This Matlab demo works as a proof of concept for the main ideas in the paper.
  </i> </p>  