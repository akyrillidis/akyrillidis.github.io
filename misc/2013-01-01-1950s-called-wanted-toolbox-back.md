---
title: "The 1950s called and wanted their toolbox back"
description: "Your favourite fancy-pants modern programming language is from the 1950s. Pretty much any programming language used today is a derivative of Fortran or Lisp, both born in the 1950s. Okay, reality check: It’s 2013—yes, 60 years later—and we have cars that drive themselves on the street, robots roaming the surface of alien planets and tiny networked devices with interactive surfaces that we keep in our pockets, which are orders of magnitude more powerful than the computers of the 1950s."
og_image_url: http://farm9.staticflickr.com/8358/8336375923_9f0dca4da9_o.png
layout: post
tags: programming
category: languages
comments: yes
---

<img src="http://farm9.staticflickr.com/8358/8336375923_9f0dca4da9_o.png" width="50%" align="right">Your favourite fancy-pants modern programming language is from the 1950s.

Pretty much any programming language used today is [a derivative](http://www.levenez.com/lang/) of [Fortran](http://en.wikipedia.org/wiki/Fortran) or [Lisp](http://en.wikipedia.org/wiki/Lisp_%28programming_language%29), both born in the 1950s. Okay, reality check: It's 2013—yes, 60 years later—and we have cars that drive themselves on the street, robots roaming the surface of alien planets and tiny networked devices with interactive surfaces that we keep in our pockets, which are orders of magnitude more powerful than the computers of the 1950s.

This might come as a surprise to readers not into [computer programming](http://en.wikipedia.org/wiki/Computer_programming), but professional and hobbyist programmers alike all ***use the same tools as we did 60 years ago*** — one-dimensional, sequential plain text. It's like writing a single document in Word *without using any formatting*, with the goal of instructing a large symphony orchestra to perform a complex musical piece. That app you're using could as well have been built in the 1950s, had we the same powerful hardware back then. We are thoughtlessly using Grandpa's old toolbox to build a spaceship.

The [Wikipedia article on computer programming](http://en.wikipedia.org/wiki/Computer_programming) opens up with the following description:

> Computer programming […] is the process of designing, writing, testing, debugging, and maintaining the source code of computer programs.

Interestingly "writing" is an inherent part of this canonical description of "computer programming" — a subject under constant scrutiny. Programming has become synonymous with "writing code", which really tickles my LOL, so to speak.

## Jumping higher & beyond the written text

Writing is a universal tool we created for conveying information in a way that can be easily copied, shared and distributed. Although writing as a form of communication goes as far back as 5200 years (clay tablets used in Mesopotamia around 3200 BCE), we would not reach an interesting level of literacy until the [late 19th century](http://en.wikipedia.org/wiki/File:Illiteracy_france.png) when reading was no longer exclusive to monks, academics and the educated upper class, but became an extremely important tool of humanity, propelling us into the industrial age and beyond. As a species we are builders. In a way, we have taken control of our evolution not by changing our minds or physique, to become larger so we can build greater things, but by building a tower of knowledge that enables us to create small and large tools which in turn enables us to build houses taller than a hundred people and explore the surface of alien planets no human has ever set a foot on.

Just as the now mundane tools pen and paper have evolved from blood and cave walls into sharp stones and clay tablets—into ink and papyrus into pen and paper and lately into stylus and screen—the fundamental tools (i.e. computer programming) we use today to build tomorrow's toolbox (i.e. software) have not evolved to make use of our current arsenal of technology. How will we build software 20 years from now? 200 years from now? Hopefully not limited by the same factors as we are today, namely expressing multi-dimensional and naturally concurrent systems in one-dimensional, sequential text.

![High jump](http://farm9.staticflickr.com/8078/8337433556_d3104c8b59_o.png)

We seem to have reached an upper level of utility with our current toolbox for programming computers, much like the athletic Olympic sport of [High Jump](http://en.wikipedia.org/wiki/High_jump), where the current record of 2.45m has remained for 20 years — here we have reached the limit of the tool box (the human body.) To allow High Jump to "progress" further, we would either need to change the definition and rules of the sport or allow modified human bodies (i.e. doping, cybernetics, etc) to participate.

Our current toolbox for software creation has an inherent limitation at its very foundation: low bandwidth. One-dimensional, sequential text utilises only our sense of sight, and is interpreted by a small section of our brains, forming a "bridge" or "proxy" for meaning and expression.

The high-level goal of computer programming is to enable the creation of highly customised tools: A video player app is a tool for playing specific kinds of moving pictures synchronised with audio. The game on your smartphone that you play on the bus is a tool for creating feelings of accomplishment. The system of a bank is a specialised tool that keeps track of who has what money.

## What about tomorrow?

So how do we make full use of today's technology to enable these very creative individuals known as computer programmers—or rather; software engineers—to jump even higher? I doubt a thousand year old one-dimensional tool like text is the answer, when we perform other tasks in life using tools which make better use of our senses — touch and hearing, and don't forget the higher-level senses like image recognition and spatial ability. Our minds are truly powerful and very able.

So it all comes down to [Human-Computer Interaction](http://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction), the field of interaction between people and computers. Programming is, in fact, just an interface *for* humans *to control* computers.

A good example is the car. If you owned a car in the 1800s you would know how to maintain that car. You would know how the engine operated, and you would be able to diagnose and fix problems. Today you simply press a button to start or stop the car. Open up the engine compartment hood of a modern car and you will probably just see a large flat surface with a logotype on it — the heart of the car has become irrelevant knowledge for most car operators like yourself.

<img src="http://farm9.staticflickr.com/8491/8336375797_bea36eb333_o.png" width="30%" align="right">The car of the 1800s would not be a very useful tool in today's measures as it would likely break down during short trips, would not go very fast and was expensive to produce and operate. The car of today is an extremely able tool which extends your ability of transportation both in terms of time (speed), comfort, distance and freight. We have refined our tools (hammers and screwdrivers replaced by robotic specialised factories and lasers) by applying the process of interface abstraction to in order to make the human able to do more using less cognitive effort. They year of 2012 even brought us street-legal [cars which drives themselves](http://newsfeed.time.com/2012/09/26/speeding-into-the-future-self-driving-cars-are-now-legal-in-california/) — a step further in the progress of abstraction, enabling us not only to transport ourselves long distances in comfort, but also free up time for other tasks (i.e. while the car is driving.)

The field of programming need to see a renaissance in fundamental reinvention, just as it did in the 1950s when programming machines using levers and buttons was replaced by programming machines using textual sequences of computer commands.

![Minority report FTW](http://farm9.staticflickr.com/8072/8337458910_786074443c_o.png)

Okay, maybe we're not in the movie Minority Report just yet, but still, today's multi-sensory input-output technology like high-density interactive [touch screens which "touches back"](http://www.technologyreview.com/news/417879/touch-screens-that-touch-back/) and [spatial 3D positional audio](http://www.hitl.washington.edu/scivw/EVE/I.B.1.3DSoundSynthesis.html) are all interesting technology that just now have become economically viable and high-fidelity enough to be forgotten — "forgotten" as in us no longer thinking about the technology itself, but to be able to intuitively focus on whatever is presented and conveyed.

## Visions for the future, from the past

In the rather profound [Design Principles Behind Smalltalk](http://www.cs.virginia.edu/~evans/cs655/readings/smalltalk.html) in which [Daniel Ingalls](http://en.wikipedia.org/wiki/Daniel_Henry_Holmes_Ingalls%2C_Jr.) of the Xerox PARC expresses the interesting ethos of enabling creative individuals to program computers, we can read the following:

> [...] a vision that includes a creative individual and the best computing hardware available.

Ingalls builds further on this vision, writing:

> If a system is to serve the creative spirit, it must be entirely comprehensible to a single individual.
>
> The point here is that the human potential manifests itself in individuals. To realize this potential, we must provide a medium that can be mastered by a single individual. Any barrier that exists between the user and some part of the system will eventually be a barrier to creative expression.

Back in 1981 when the above document was published, human-computer hardware interfaces were far from as high fidelity as they are today. There were no low-latency touch screens you could hold in your hand and there were no graphics processors able to render complex movie scenes on-the fly. Keyboards were still the lowest friction and efficient way for a human to provide a computer with input. With today's hi-fi user input hardware we should be able to further lower the friction—the "barrier"—between the human and the computer, and at the same time also increase the bandwidth of communication.

As early as 1963 was alternative human-computer interaction hardware with potentially lower level of friction and higher bandwidth explored. Most notably is [Sketchpad](http://en.wikipedia.org/wiki/Sketchpad), which used a stylus pen with an interactive screen, as likely being the most significant invention in the field of HCI.

Below here is a video of [Alan Kay](http://en.wikipedia.org/wiki/Alan_Kay)'s famous talk ["Doing with Images Makes Symbols"](http://archive.org/details/AlanKeyD1987) from 1987 in which we see both Sketchpad and GrAIL (another early graphical programming environment from 1968) in action:

<iframe src="http://archive.org/embed/AlanKeyD1987" width="640" height="480" frameborder="0" allowFullScreen></iframe><br>
<small><em>Sketchpad segment start at 04:00. GrAIL segment starts at at 24:10.</em></small>

Not only was Sketchpad the first ever stylus input device, but also pioneered graphical windows and object-oriented programming. The computer it ran on was large enough to have it's own roof and had a total memory of 460 kilobytes (a small photo from your smartphone is likely to be 2-4 times *larger* that the entire memory of this machine), and the processor could perform 400 000  instructions per second. Your average smartphone today can perform around 4 000 000 000 instructions per second (per core) — that means that what's in your pocket today is not only extremely small in comparison to the giant computer Sketchpad was running on in 1963, but is also 10 000 times more powerful.

Now, remember the 1950s called and still haven't got their programming toolbox back.
